![coval](coval.png)

# Intelligent Code Generation, Execution, and Repair ğŸ¤– COVAL Developer Assistant  

![COVAL](https://img.shields.io/badge/COVAL-v2.0-blue.svg)
![Python](https://img.shields.io/badge/Python-3.11+-green.svg)
![Docker](https://img.shields.io/badge/Docker-Required-blue.svg)
![Ollama](https://img.shields.io/badge/Ollama-Required-orange.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)

**COVAL** is a comprehensive Python package for intelligent code generation, execution, and deployment with multiple LLM models. It features robust content cleaning, Docker containerization, health monitoring, and automated deployment workflows for building production-ready applications.

## âœ¨ Key Features
- ğŸ¤– **Multi-Model Support**: Qwen, DeepSeek, CodeLlama, Granite, and more
- ğŸ§¹ **Smart Content Cleaning**: Removes merge conflicts and invalid patterns
- ğŸ³ **Docker Integration**: Automated containerization and deployment  
- ğŸ” **Health Monitoring**: Container health checks and status tracking
- ğŸ“Š **Debug Logging**: Comprehensive logging for troubleshooting
- ğŸš€ **Production Ready**: Tested deployment workflows


```
                    START
                      â”‚
                  [TRIAGE]
                      â”‚
              Collect Metrics
                      â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  DECISION MODEL   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
           C_fix > 1.5 * C_new?
                 â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                YES        NO
                 â”‚          â”‚
            [REBUILD]   [REPAIR]
                 â”‚          â”‚
           Recommend      MRE
           Rebuilding   Creation
                 â”‚          â”‚
                END    Fix Generation
                           â”‚
                      Validation
                      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                   PASS        FAIL
                     â”‚          â”‚
                 [SUCCESS]  Retry?
                     â”‚      â”Œâ”€â”€â”´â”€â”€â”
                    END    YES   NO
                            â”‚     â”‚
                      Next Iter  END
```



## ğŸš€ Quick Start

```bash
# 1. Install dependencies
pip install -e .

# 2. Generate new code with specific model
coval generate -d "Create a FastAPI app with user authentication" \
  -f fastapi -l python \
  --features "user registration" --features "JWT tokens" \
  --model qwen



# 3. Deploy generated code
coval run --iteration <iteration_name>

# 4. Check deployed containers
docker ps | grep coval-

# 5. Access your app
curl http://localhost:8001/health
```

## ğŸ“‹ Available Models

```bash
# Recommended models (configure in llm.config.yaml)
--model qwen          # Qwen 2.5 Coder (recommended for code generation)
--model deepseek      # DeepSeek Coder (good for analysis)
--model deepseek-r1   # DeepSeek R1 (reasoning-focused)
--model codellama13b  # CodeLlama 13B (large context)
--model granite       # Granite Code (enterprise)
--model mistral       # Mistral (fallback)
```

## âœ¨ Key Features

### ğŸ”„ **Iterative Code Management**
- **Intelligent Iteration System**: Each generation/repair creates a new versioned iteration
- **Cost-Based Decisions**: Automatic analysis of whether to modify existing code or generate new
- **Legacy Cleanup**: Automatic removal of old iterations with configurable retention policies
- **History Tracking**: Complete audit trail of all code changes and decisions


```
1. INPUT
   â”œâ”€â”€ Error File (stacktrace/logs)
   â”œâ”€â”€ Source Directory
   â””â”€â”€ Test File (optional)
          â†“
2. TRIAGE
   â”œâ”€â”€ Calculate Technical Debt
   â”œâ”€â”€ Measure Test Coverage
   â”œâ”€â”€ Assess Available Context
   â””â”€â”€ Get Model Capability
          â†“
3. DECISION
   â”œâ”€â”€ Calculate Repair Cost
   â”œâ”€â”€ Calculate Rebuild Cost
   â””â”€â”€ Make Decision (repair/rebuild)
          â†“
4. MRE CREATION [if repair]
   â”œâ”€â”€ Copy Relevant Files
   â”œâ”€â”€ Create Dockerfile
   â””â”€â”€ Generate README
          â†“
5. FIX GENERATION
   â”œâ”€â”€ Prepare Context
   â”œâ”€â”€ Generate Prompt
   â”œâ”€â”€ Call LLM
   â””â”€â”€ Parse Response
          â†“
6. VALIDATION
   â”œâ”€â”€ Apply Patch
   â”œâ”€â”€ Build Container
   â”œâ”€â”€ Run Tests
   â””â”€â”€ Check Results
          â†“
7. INTEGRATION
   â”œâ”€â”€ Save Final Patch
   â”œâ”€â”€ Generate Report
   â””â”€â”€ Return Result
```

### ğŸ¤– **Multi-LLM Code Generation & Repair** 
- **6 Specialized Models**: Qwen, DeepSeek-R1, CodeLlama 13B, DeepSeek, Granite, Mistral
- **Adaptive Model Selection**: Choose optimal model based on task complexity and context
- **Automatic Model Management**: Download and configure models automatically via Ollama
- **Dynamic Capability Calculation**: Real-time model performance assessment

### ğŸ³ **Transparent Docker Deployments**
- **Blue-Green Deployments**: Zero-downtime deployments with automatic rollback
- **Volume Overlays**: Expose only latest changes while preserving legacy code
- **Multi-Framework Support**: FastAPI, Flask, Express.js, Next.js templates
- **Health Monitoring**: Automatic health checks and failure detection

### ğŸ’¡ **Intelligent Cost Analysis**
- **Cost Calculator**: Automatically decides between modifying existing code vs generating new
- **Multi-Factor Analysis**: Considers technical debt, scope, complexity, and historical success
- **Risk Assessment**: Evaluates confidence levels and potential regression risks
- **Optimization Suggestions**: Recommends best approach for each scenario



## ğŸ“‹ CLI Commands

### `coval generate` - Generate New Code
```bash
# Basic generation
coval generate -d "Create a REST API for user management" --model deepseek-r1

coval generate -d "Create a REST API for user management" --model qwen  --deploy


# Specify framework and features
coval generate -d "Build a blog platform" -f fastapi -l python \
  --features "authentication" --features "database" --deploy

# Generate from parent iteration
coval generate -d "Add payment system" --parent iter-001 --model deepseek-r1
```

### `coval run` - Deploy Iterations
```bash
# Deploy latest iteration
coval run

# Deploy specific iteration
coval run -i iter-003 -p 8080

# Use different deployment strategy
coval run -i iter-002 --strategy copy
```

### `coval repair` - Fix Code Issues
```bash
# Basic repair
coval repair -e logs/error.log

# Advanced repair with specific model
coval repair -e error.log -i iter-002 --model codellama13b --deploy

# Analyze only (no repair)
coval repair -e error.log --analyze
```

### `coval status` - Project Overview
```bash
# Show all iterations and deployments
coval status

# Verbose output
coval status -v
```

### `coval cleanup` - Maintenance
```bash
# Keep only 10 most recent iterations
coval cleanup -c 10

# Force cleanup without confirmation
coval cleanup -c 5 --force
```

### `coval stop` - Stop Deployments
```bash
# Stop specific deployment
coval stop -i iter-003

# Stop all deployments
coval stop
```

## ğŸ›  Installation


## ğŸ§° Makefile Automation

The repository includes a comprehensive `Makefile` that streamlines the full development and release workflow. Use the commands below to get productive quickly:

### Environment & Dependencies

```bash
make setup          # Create virtualenv and install dev dependencies
make install        # Install runtime dependencies only
make install-docs   # Install documentation toolchain
```

### Code Quality & Testing

- **`make format`** â€“ Format the codebase with Black.
- **`make lint`** â€“ Run Black, Flake8, and MyPy checks.
- **`make test`** â€“ Execute the full pytest suite with coverage.
- **`make quick-test`** â€“ Fast iteration loop (`format` + `test-fast`).
- **`make full-check`** â€“ Complete verification (`format`, `lint`, `test`, `security-check`).

### Build & Deployment

- **`make build`** â€“ Produce source and wheel distributions.
- **`make docker-build`** â€“ Build the Docker image tagged with the current version and `latest`.
- **`make deploy-local`** â€“ Build artifacts and run the Docker container locally.

### Release Automation

- **`make publish`** â€“ Automatically bumps the patch version, builds the project, and uploads it to PyPI.
- **`make publish-test`** â€“ Publish artifacts to TestPyPI.
- **`make publish-docker`** â€“ Push Docker images to the configured registry.
- **`make release-patch`**, **`make release-minor`**, **`make release-major`** â€“ Run quality gates, bump versions, build artifacts, and publish to PyPI & Docker.

> **Note:** The `make publish` target automatically increments the patch version via `make version-patch` before uploading. This prevents accidental attempts to reuse an existing version on PyPI.

### Version Management Workflow

```bash
make version          # Display current version and active git branch
make version-patch    # Bump X.Y.Z â†’ X.Y.(Z+1), commit, and tag
make version-minor    # Bump X.Y.Z â†’ X.(Y+1).0, commit, and tag
make version-major    # Bump X.Y.Z â†’ (X+1).0.0, commit, and tag
```

Each command updates `setup.py` and `coval/__init__.py`, creates a git commit, and produces an annotated tag (e.g., `v2.0.1`).

For full releases:

```bash
make release-patch    # format/lint/test â†’ version-patch â†’ build â†’ publish â†’ docker-push
make release-minor
make release-major
```

If a publication fails after a version bump, you can roll back by deleting the tag and resetting the commit:

```bash
git tag -d v<new_version>
git reset --hard HEAD^   # restore previous commit
```


### Prerequisites
```bash
# System requirements
Python 3.11+
Docker & Docker Compose
Ollama (for LLM models)

# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama serve
```

### Install COVAL
```bash
# Clone repository
git clone https://github.com/your-org/coval.git
cd coval

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install package
pip install -e .

# Verify installation
coval --help
```

Or use the Makefile helper (recommended):

```bash
make setup            # Creates venv, installs runtime + dev dependencies
source venv/bin/activate
coval --help
```

## âš™ï¸ Configuration

### Project Configuration (`coval.config.yaml`)
```yaml
# Project settings
project:
  name: "my-coval-project"
  framework: "auto-detect"
  language: "auto-detect" 
  max_iterations: 50

# Docker deployment settings  
docker:
  base_port: 8000
  network_name: "coval-network"
  auto_cleanup: true

# Volume overlay strategy
volumes:
  strategy: "overlay"  # overlay, copy, symlink
  preserve_permissions: true

# Cost calculation settings
cost_calculation:
  modify_base_cost: 10.0
  generate_base_cost: 25.0
  complexity_multiplier: 2.0
```

### LLM Configuration (`llm.config.yaml`)
```yaml
models:
  qwen2.5-coder:
    model_name: "qwen2.5-coder:7b"
    max_tokens: 16384
    temperature: 0.2
    base_capability: 0.85
    context_window: 32768
    
  deepseek-r1:
    model_name: "deepseek-r1:7b" 
    max_tokens: 12288
    temperature: 0.1
    base_capability: 0.80
    context_window: 16384
```

### ğŸ”„ **Automatyczne Pobieranie Modeli**
System automatycznie sprawdza dostÄ™pnoÅ›Ä‡ modelu via `ollama list` i pobiera brakujÄ…ce:
```bash
ğŸ” Sprawdzam dostÄ™pnoÅ›Ä‡ modelu: deepseek-r1:7b
ğŸ“¥ Pobieram model: deepseek-r1:7b
âœ… PomyÅ›lnie pobrano model: deepseek-r1:7b
```

## Kluczowe funkcjonalnoÅ›ci:

### 1. **Model Decyzyjny Repair vs Rebuild**
- Implementuje matematyczny model kosztu naprawy: `C_fix = Î³D * (1/S) * (1/K) * (1 + Î»(1-T))`
- Oblicza prawdopodobieÅ„stwo sukcesu uÅ¼ywajÄ…c **funkcji logitowej**
- Automatycznie decyduje czy naprawiaÄ‡ czy przebudowaÄ‡

### 2. **Workflow Naprawy (MRE â†’ Test â†’ Patch â†’ Walidacja)**
- **Triage**: Analiza problemu i zbieranie metryk
- **MRE**: Tworzenie Minimal Reproducible Example
- **Generowanie**: UÅ¼ywa LLM do tworzenia poprawek
- **Walidacja**: Automatyczne testy w Docker
- **Integracja**: Finalizacja i raportowanie

### 3. **Metryki i Analiza**
- DÅ‚ug techniczny (zÅ‚oÅ¼onoÅ›Ä‡, duplikacja, brak dokumentacji)
- Pokrycie testami
- DostÄ™pny kontekst (stacktrace, testy, dokumentacja)
- ZdolnoÅ›ci modelu LLM

### 4. **Struktura FolderÃ³w**
```
/repairs/
  /repair-{ticket-id}/
    /mre/           # Minimal Reproducible Example
    /proposals/     # Propozycje napraw
    /validation/    # Wyniki walidacji
    decision.md     # Decyzja repair vs rebuild
    repair_report.md # Raport koÅ„cowy
```

### 5. **UÅ¼ycie CLI v2.0**

#### **DostÄ™pne Modele:**
```bash
--model qwen         # qwen2.5-coder:7b (domyÅ›lny, 95% zdolnoÅ›ci)
--model deepseek     # deepseek-coder:6.7b (80% zdolnoÅ›ci)
--model codellama13b # codellama:13b (75% zdolnoÅ›ci, duÅ¼y kontekst)
--model deepseek-r1  # deepseek-r1:7b (88% zdolnoÅ›ci, reasoning)
--model granite      # granite-code:8b (70% zdolnoÅ›ci, enterprise)
--model mistral      # mistral:7b (60% zdolnoÅ›ci, fallback)
```



### 6. **Inteligentne Funkcje v2.0**

- **Automatyczne pobieranie modeli** - System sprawdza `ollama list` i pobiera brakujÄ…ce modele
- **Dynamiczne obliczanie zdolnoÅ›ci** - UwzglÄ™dnia tokeny, temperaturÄ™, kontekst i historiÄ™
- **Adaptacyjne uczenie siÄ™** - 8 kategorii problemÃ³w z historical tracking
- **Automatyczne wykrywanie jÄ™zyka/frameworka** - dostosowuje Dockerfile i proces walidacji
- **Iteracyjne poprawki** - do 5 prÃ³b z rÃ³Å¼nymi podejÅ›ciami i konfiguracjÄ… z YAML
- **Parsowanie bÅ‚Ä™dÃ³w** - wyciÄ…ga pliki wymienione w stacktrace
- **Generowanie promptÃ³w** - rÃ³Å¼ne szablony dla pierwszej i kolejnych prÃ³b
- **Walidacja w kontenerach** - izolowane Å›rodowisko testowe
- **Konfigurowalne parametry** - Wszystkie ustawienia modeli w `llm.config.yaml`


## ğŸ”§ **Troubleshooting**

### **Problemy z Ollama:**
```bash
# Ollama nie jest zainstalowane
âŒ Ollama nie jest zainstalowane lub nie jest w PATH
âœ… RozwiÄ…zanie: curl -fsSL https://ollama.com/install.sh | sh

# Model nie moÅ¼e byÄ‡ pobrany
âŒ BÅ‚Ä…d pobierania modelu: connection refused
âœ… RozwiÄ…zanie: Uruchom ollama serve w osobnym terminalu

# Timeout pobierania
â±ï¸ Timeout przy pobieraniu modelu: deepseek-r1:7b
âœ… RozwiÄ…zanie: ZwiÄ™ksz timeout lub pobierz rÄ™cznie: ollama pull deepseek-r1:7b
```

### **Problemy z KonfiguracjÄ…:**
```bash
# Brak llm.config.yaml
âŒ Nie moÅ¼na zaÅ‚adowaÄ‡ konfiguracji
âœ… RozwiÄ…zanie: Skopiuj llm.config.yaml z repozytorium

# NieprawidÅ‚owa konfiguracja YAML
âŒ yaml.parser.ParserError
âœ… RozwiÄ…zanie: SprawdÅº skÅ‚adniÄ™ YAML online (yamllint.com)

# Brak uprawnieÅ„ do zapisu repair_history.json
âŒ Permission denied: repairs/repair_history.json
âœ… RozwiÄ…zanie: mkdir -p repairs && chmod 755 repairs
```

### **Problemy z Modelami:**
```bash
# Model nie odpowiada
âŒ Model timeout po 60s
âœ… RozwiÄ…zanie: UÅ¼yj mniejszego modelu (--model mistral) lub zwiÄ™ksz timeout

# NiewystarczajÄ…ca pamiÄ™Ä‡
âŒ CUDA out of memory
âœ… RozwiÄ…zanie: UÅ¼yj CPU: CUDA_VISIBLE_DEVICES="" python3 repair.py

# Model daje zÅ‚e wyniki
âŒ Repair failed repeatedly
âœ… RozwiÄ…zanie: SprÃ³buj innego modelu z wiÄ™kszymi zdolnoÅ›ciami (--model deepseek-r1)
```

### **Customizacja dla WÅ‚asnych Potrzeb:**

#### **ZwiÄ™ksz ZdolnoÅ›ci Modelu:**
```yaml
models:
  custom-qwen:
    base_capability: 0.90      # â†‘ WyÅ¼sza baza
    max_tokens: 32768          # â†‘ WiÄ™cej tokenÃ³w = bonus
    temperature: 0.1           # â†“ NiÅ¼sza temperatura = mniej penalty
    context_window: 65536      # â†‘ WiÄ™kszy kontekst = bonus
```

#### **Dostosuj dla Åšrodowiska Produkcyjnego:**
```yaml
global:
  timeout: 120                 # â†‘ WiÄ™cej czasu dla zÅ‚oÅ¼onych napraw
  max_iterations: 10           # â†‘ WiÄ™cej prÃ³b
  adaptive_evaluation:
    history_weight: 0.5        # â†‘ WiÄ™ksza waga dla historii
    min_samples: 10            # â†‘ WiÄ™cej danych do oceny
```

#### **Optymalizacja dla SzybkoÅ›ci:**
```yaml
models:
  fast-mistral:
    max_tokens: 4096           # â†“ Mniej tokenÃ³w = szybciej
    temperature: 0.4           # â†‘ WyÅ¼sza = mniej precyzyjne ale szybsze
    retry_attempts: 1          # â†“ Mniej prÃ³b
```

### 7. **Raporty i Decyzje**

System generuje szczegÃ³Å‚owe raporty zawierajÄ…ce:
- AnalizÄ™ kosztÃ³w (repair vs rebuild)
- PrawdopodobieÅ„stwo sukcesu
- Zastosowane poprawki
- OcenÄ™ ryzyka regresji
- Rekomendacje dalszych krokÃ³w

### 8. **Wsparcie dla wielu jÄ™zykÃ³w**

Automatycznie rozpoznaje i obsÅ‚uguje:
- Python (FastAPI, Django, Flask)
- JavaScript/Node.js (Express, Next.js)
- Go (Gin, Fiber)
- Rust, Java, Ruby, PHP

Skrypt jest w peÅ‚ni zintegrowany z podejÅ›ciem YMLL i implementuje wszystkie najlepsze praktyki z REPAIR_GUIDELINES, zapewniajÄ…c efektywny i powtarzalny proces naprawiania kodu z pomocÄ… LLM.

## Funkcja logitowa

Funkcja **logitowa** to po prostu funkcja matematyczna uÅ¼ywana gÅ‚Ã³wnie w statystyce i uczeniu maszynowym do przeksztaÅ‚cania prawdopodobieÅ„stw w tzw. log-odds. Jest odwrotnoÅ›ciÄ… funkcji sigmoidalnej (logistycznej).

DokÅ‚adniej:

### Definicja

JeÅ¼eli $p$ to prawdopodobieÅ„stwo zdarzenia (0 < p < 1), funkcja logitowa jest zdefiniowana jako:

$$
\text{logit}(p) = \ln\left(\frac{p}{1-p}\right)
$$

* $p/(1-p)$ to **odds** (szansa, Å¼e zdarzenie nastÄ…pi vs Å¼e nie nastÄ…pi)
* $\ln$ to logarytm naturalny

### PrzykÅ‚ad

* JeÅ›li $p = 0.8$ (80% prawdopodobieÅ„stwa),

$$
\text{logit}(0.8) = \ln\left(\frac{0.8}{0.2}\right) = \ln(4) \approx 1.386
$$

* JeÅ›li $p = 0.5$, $\text{logit}(0.5) = \ln(1) = 0$

### Zastosowanie

* W **regresji logistycznej** logit przeksztaÅ‚ca prawdopodobieÅ„stwa w wartoÅ›Ä‡ na osi liczbowej od $-\infty$ do $+\infty$, co pozwala modelowi liniowemu prognozowaÄ‡ log-odds, a nastÄ™pnie Å‚atwo przeksztaÅ‚caÄ‡ z powrotem w prawdopodobieÅ„stwo.
* W twoim kontekÅ›cie (system naprawy kodu) funkcja logitowa moÅ¼e sÅ‚uÅ¼yÄ‡ do obliczenia **prawdopodobieÅ„stwa sukcesu naprawy** na podstawie rÃ³Å¼nych zmiennych (jak zÅ‚oÅ¼onoÅ›Ä‡, dostÄ™pnoÅ›Ä‡ testÃ³w itd.).


